{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_path = \"/Users/a1/Desktop/News/dataset/News Articles/\"\n",
    "summaries_path = \"/Users/a1/Desktop/News/dataset/Summaries/\"\n",
    "articles_dir = pathlib.Path(articles_path)\n",
    "summaries_dir = pathlib.Path(summaries_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_pathlist = list(articles_dir.iterdir())\n",
    "summaries_pathlist = list(summaries_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(folder):\n",
    "    data = []\n",
    "    count = 0\n",
    "    for file in os.listdir(folder):\n",
    "        try:\n",
    "            text = ''\n",
    "            name = file\n",
    "            myfile = open(str(folder) + '/' + file, \"r\")\n",
    "            text = myfile.read()\n",
    "            #mylist = [name, text]\n",
    "            count += 1\n",
    "            data.append(text)\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Task Finished!\")\n",
    "    print(str(count) + \" text files\")\n",
    "    \n",
    "    return data, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Finished!\n",
      "386 text files\n",
      "Task Finished!\n",
      "510 text files\n",
      "Task Finished!\n",
      "510 text files\n",
      "Task Finished!\n",
      "417 text files\n",
      "Task Finished!\n",
      "401 text files\n",
      "Task Finished!\n",
      "386 text files\n",
      "Task Finished!\n",
      "510 text files\n",
      "Task Finished!\n",
      "510 text files\n",
      "Task Finished!\n",
      "417 text files\n",
      "Task Finished!\n",
      "401 text files\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "summaries = []\n",
    "\n",
    "for e in articles_pathlist:\n",
    "    data, count = generate_data(e)\n",
    "    articles.extend(data)\n",
    "\n",
    "for e in summaries_pathlist:\n",
    "    data, count = generate_data(e)\n",
    "    summaries.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles # : 2224\n",
      "Summaries # : 2224\n"
     ]
    }
   ],
   "source": [
    "print('Articles # : ' + str(len(articles)))\n",
    "print('Summaries # : ' + str(len(summaries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    # Replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w) \n",
    "    # Reducing spaces\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # lower case\n",
    "    w = w.lower()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(articles)):\n",
    "    articles[i] = preprocess_sentence(articles[i])\n",
    "    \n",
    "for i in range(len(summaries)):\n",
    "    summaries[i] = preprocess_sentence(summaries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)\n",
    "len(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "articles = pd.DataFrame(articles)\n",
    "summaries = pd.DataFrame(summaries)\n",
    "data = pd.concat([articles, summaries], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['articles', 'summaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>musicians to tackle us red tape musicians grou...</td>\n",
       "      <td>nigel mccune from the musicians union said bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u s desire to be number one u , who have won t...</td>\n",
       "      <td>but they still want more.they have to want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rocker doherty in on stage fight rock singer p...</td>\n",
       "      <td>babyshambles, which he formed after his acrimo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snicket tops us box office chart the film adap...</td>\n",
       "      <td>a series of unfortunate events also stars scot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>ocean s twelve, the crime caper sequel starrin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles  \\\n",
       "0  musicians to tackle us red tape musicians grou...   \n",
       "1  u s desire to be number one u , who have won t...   \n",
       "2  rocker doherty in on stage fight rock singer p...   \n",
       "3  snicket tops us box office chart the film adap...   \n",
       "4  ocean s twelve raids box office ocean s twelve...   \n",
       "\n",
       "                                           summaries  \n",
       "0  nigel mccune from the musicians union said bri...  \n",
       "1  but they still want more.they have to want to ...  \n",
       "2  babyshambles, which he formed after his acrimo...  \n",
       "3  a series of unfortunate events also stars scot...  \n",
       "4  ocean s twelve, the crime caper sequel starrin...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summaries'] = data['summaries'].apply(lambda x : '_START_' + x + '_END_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles :  musicians to tackle us red tape musicians groups are to tackle us visa regulations which are blamed for hindering british acts chances of succeeding across the atlantic. a singer hoping to perform in the us can expect to pay , simply for obtaining a visa. groups including the musicians union are calling for an end to the raw deal faced by british performers. us acts are not faced with comparable expense and bureaucracy when visiting the uk for promotional purposes. nigel mccune from the musicians union said british musicians are disadvantaged compared to their us counterparts. a sponsor has to make a petition on their behalf, which is a form amounting to nearly pages, while musicians face tougher regulations than athletes and journalists. if you make a mistake on your form, you risk a five year ban and thus the ability to further your career, says mr mccune. the us is the world s biggest music market, which means something has to be done about the creaky bureaucracy, says mr mccune. the current situation is preventing british acts from maintaining momentum and developing in the us, he added. the musicians union stance is being endorsed by the music managers forum mmf , who say british artists face an uphill struggle to succeed in the us, thanks to the tough visa requirements, which are also seen as impractical. the mmf s general secretary james seller said imagine if you were an orchestra from the orkneys? every member would have to travel to london to have their visas processed. the us market is seen as the holy grail and one of the benchmarks of success, and we re still going to fight to get in there. it s still very important, but there are other markets like europe, india and china, added mr seller. a department for media, culture and sport spokeswoman said we re aware that people are experiencing problems, and are working with the us embassy and record industry to see what we can do about it. a us embassy spokesman said we are aware that entertainers require visas for time specific visas and are doing everything we can to process those applications speedily. we are aware of the importance of cultural exchange and we will do our best to facilitate that, he added. \n",
      "Summaries :  _START_nigel mccune from the musicians union said british musicians are disadvantaged compared to their us counterparts.a us embassy spokesman said we are aware that entertainers require visas for time specific visas and are doing everything we can to process those applications speedily. the musicians union stance is being endorsed by the music managers forum mmf , who say british artists face an uphill struggle to succeed in the us, thanks to the tough visa requirements, which are also seen as impractical.musicians groups are to tackle us visa regulations which are blamed for hindering british acts chances of succeeding across the atlantic. the us is the world s biggest music market, which means something has to be done about the creaky bureaucracy, says mr mccune. the current situation is preventing british acts from maintaining momentum and developing in the us, he added.a singer hoping to perform in the us can expect to pay , simply for obtaining a visa._END_\n"
     ]
    }
   ],
   "source": [
    "print(\"Articles : \", data['articles'][0])\n",
    "print(\"Summaries : \", data['summaries'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_max_len = 500\n",
    "summaries_max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(data['articles'], data['summaries'], test_size=0.1, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_tokenizer.texts_to_sequences(x_train)\n",
    "x_val = x_tokenizer.texts_to_sequences(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, \n",
    "                        maxlen=articles_max_len, \n",
    "                        padding='post')\n",
    "x_val = pad_sequences(x_val, \n",
    "                    maxlen=articles_max_len, \n",
    "                    padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_voc_size = len(x_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 500)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_val = y_tokenizer.texts_to_sequences(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pad_sequences(y_train, \n",
    "                        maxlen=summaries_max_len, \n",
    "                        padding='post')\n",
    "y_val = pad_sequences(y_val, \n",
    "                    maxlen=summaries_max_len, \n",
    "                    padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_voc_size = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 100)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_100d_dictionary(GLOVE_DIR):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join('/Users/a1/Desktop/', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = x_tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-b68b05934197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hello'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Hello'"
     ]
    }
   ],
   "source": [
    "print(embeddings_index[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
